
\documentclass[journal]{IEEEtran}
% \documentclass[conference]{IEEEtran
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{scrextend}
\usepackage{algorithmic}
\usepackage{graphicx} 
\graphicspath{{./figures/}{../png/} }
\usepackage{subfig}
\usepackage{wrapfig}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

% This is to include code
\usepackage{listings}
\usepackage{xcolor}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\lstdefinestyle{Python}{
    language        = Python,
    basicstyle      = \ttfamily,
    keywordstyle    = \color{blue},
    keywordstyle    = [2] \color{teal},
    stringstyle     = \color{green},
    commentstyle    = \color{red}\ttfamily}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}

\newenvironment{theorem}[2][Theorem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{lemma}[2][Lemma]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{exercise}[2][Exercise]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{reflection}[2][Reflection]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{proposition}[2][Proposition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{corollary}[2][Corollary]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

\hyphenation{op-tical net-works semi-conduc-tor}

%% For our reference part
%\makeatletter
%\def\bstctlcite{\@ifnextchar[{\@bstctlcite}{\@bstctlcite[@auxout]}}
%\def\bstctlcite[#1]#2{\@bsphack\@for\@citeb:=#2\do{%
%\edef\@citeb{\expandafter\@firstofone\@citeb}%
%\if@filesw\immediate\write\csname #1\endcsname{\string\citation{\@citeb}}\fi}
%\@esphack}
%\makeatother

\begin{document}
%\bstctlcite{IEEEexample:BSTcontrol}

% --------------------------------------------------------------
%                         Start here
% --------------------------------------------------------------

\title{Evaluating the Impact of Image Normalization on Automatic Segmentation of Brain Regions}

\author{\IEEEauthorblockN{Thomas Buchegger} \IEEEauthorblockA{\textit{University of Bern,}}
\and \IEEEauthorblockN{Carolina Duran} \IEEEauthorblockA{\textit{University of Bern,}}
\and \IEEEauthorblockN{Stefan Weber,} \IEEEauthorblockA{\textit{University of Bern}}
\thanks{All authors contributed equally. Biomedical Engineering, University of Berne in Switzerland. Author's E-Mails:}%
\thanks{thomas.buchegger@students.unibe.ch}%
\thanks{carolina.duran@students.unibe.ch}%
\thanks{stefan.weber1@students.unibe.ch}}

\markboth{Medical Image Analysis Lab, January~2021}%
{}
\maketitle
%\pagestyle{plain}
\newpage


% --------------------------------------------------------------
% Abstract
% --------------------------------------------------------------

\begin{abstract}
Here is the abstract.


\end{abstract}
\hfill January 03, 2021



% --------------------------------------------------------------
% Introduction
% --------------------------------------------------------------

\section{Introduction}

	This is a very important citation test. \cite{Roohani2018}	
	Post-processes of clinical diagnosis images for treatment planning often include manual segmentation of brain regions. 
	To segment and label the brain structures in a large dataset is complicated and time-consuming by manual operator-guided segmentation. 
	Furthermore, it is affected by user variability and prone to limiting the standardisation. 
	This paper will depend upon automated segmentation that segments and labels five different brain regions. \\
	
	
	Although convoluted neuronal networks are already well used the there is still a numerous studies applying randomized forest for automatic segmentation of brain tissue. \\
	
	
	To conclude we hypothesis that normalization has no important influence in the segmentation process of brain regions. 
	We present in this paper the acquired results of no normalization and applying six normalization methods. 
	We then compare the results for every segmented brain region and for the brain regions together. 
	Furthermore, we analyse the results and conclude our findings. \\


\textbf{Our hypothesis: "Image normalization has an important influence on the segmentation".
	Aims of the introduction:
	\begin{itemize}
	\item To justify the hypothesis / aims / investigated technology
	\item To establish expectations/scope of the report
	\end{itemize} 
	Some questions which could be answered:
	\begin{itemize}
	\item Are there more powerful normalization methods?
	\item Is normalization really needed?
	\item Is the provided data already normalized in some way?
	\item Can you also unnormalize data to show a negative effect?
	\end{itemize}
	For the research:
	\begin{itemize}
	\item Understand the problem
	\item What have others already done / is there already a solution?
	\item Can I apply a solution to another problem to my problem?
	\item What lessons can I learn from others work?
	\item What deficiencies exist in others work?
	\end{itemize}
	\begin{enumerate}
	\item Demonstrate importance
		\begin{enumerate}
		\item Define the problem
		\item Explain the criticality, impact of the problem
		\end{enumerate}
	\item Demonstrate Novelty
		\begin{enumerate}
		\item Explain what is the state of the art / current practice
		\item Explain what preliminary / related work has been done towards solving the problem by you and others
		\item Explain what deficiencies / problems still exist (specifically the one that you will try to address)
		\end{enumerate}
	\item Present and Justify the Hypothesis / aim / objective
		\begin{enumerate}
		\item State Hypothesis /aim/ objective
		\item Describe evidence supporting hypothesis
		\end{enumerate}
	\item Establish expectations of the report
		\begin{enumerate}
		\item Describe scope of the presented work
		\item Present a summary of remainder of the report\\
		\end{enumerate}
	\end{enumerate} 
}

%***************************************************************************************************************	

% --------------------------------------------------------------
% Materials & Methods
% --------------------------------------------------------------

\section{Materials and Methods}

\subsection{Medical Image Analysis pipeline}
	The Medical Image Analysis (MIA) pipeline taught in the MIA Lab lectures follow the sequence of firstly perform {\itshape Registration} to T1- and T2-weighted images (T1w and T2w image), then {\itshape Pre-Process}-methods. Additionally {\itshape Feature Extraction} followed by the {\itshape Classification} of the images are performed. 
	At the end {\itshape Post-Processing}-methods are performed. Eventually, the segmentation of one patient's data set is achieved. 

\subsection{Medical Background}
	The five brain regions segmented in this paper are the white and grey matter, hippocampus, amygdala and the thalamus. All regions are visible in figure \ref{fig:e1}.

	% --------------------------------------------------------------
	\begin{figure}[h]
		\centering
		%omit extension of file. pdflatex will convert to pdf automatically.
		\includegraphics[width=0.5\textwidth]{T1native_all_regions_labelled.png}
		\caption{Ground truth picture of all brain regions to be segmented in this project.}
		\label{fig:e1}
	\end{figure}
	% --------------------------------------------------------------

\subsection{Data}
	The data used for this project was from the {\itshape Human Connectome Project} and has been provided by the Medical Image Analysis Lab team at the University of Bern. For anonymization the faces and ears of the skull have been blurred. 
	Overall, the dataset consisted of 30 MRI patient images of unrelated healthy subjects, out of which 20 were used for training and 10 for testing the model. 
	From each patient the ground truth image, the brain mask, a T1w and a T2w image were available. The images were generated by a 3 Tesla MRI. 
	The ground truth has been labelled by the silver standard and with the software FreeSurfer.
	The atlas used are the MNI152 standard-space T1-weighted average structural template images available from the {\itshape McConnell Brain Imaging Centre}\footnote{URL: \url{http://www.bic.mni.mcgill.ca/ServicesAtlases/HomePage}, Date: 23.12.2020.} (BIC) and the {\itshape NeuroImaging \& Surgical Technologies Lab}\footnote{URL: \url{http://nist.mni.mcgill.ca/?page_id=714}, Date: 23.12.2020. \label{second}}. 
	It corresponds to the MNI-ICBM atlas\footref{second} and is derived from 152 structural images, averaged together after high-dimensional nonlineal registration into this MNI152 coordinate system.
	Each MRI file is of the size 118x118x217 pixels.\smallskip
	The code was implemented in Python using scikit-learn \footnote{URL: \url{https://scikit-learn.org/stable/}, Date: 26.12.2020} and ITK\footnote{URL: \url{https://itk.org/}, Date: 26.12.2020}.
		
\subsection{Registration}
	During {\itshape Registration} the T1w and T2w image (floating image) is transformed with an affine transformation, such that it is similar to a given reference image.
	The transformation was found by an intersubjective registration from the T1w image to the provided atlas. The corresponding transformations have already been determined
	and are not part of this work. 	
	
\subsection{Preprocessing}
	The aim of {\itshape Pre-Processing} is to improve the image quality for the subsequent classification. It includes among others bias field correction, skull stripping, intensity normalization and/or histogram matching.
	Owing to the fact that the analysation and application of the impact of normalization to the realized segmentation, the used normalization techniques are described in this section.
	For this project the brain mask for skull stripping was provided. Skull stripping was performed before six different normalizations were applied to the image data. The results among all normalizations were compared to no-normalization. Primarily the used normalization methods are described. \cite{normalizations} \smallskip
		
	\subsubsection{ZScore}
	While the ZScore normalization the mean intensity value (mean) as well as the intensity standard deviation (istd) of all pixel values of the input image are calculated. 
	The image is normalized by subtracting the mean from each pixel value and then dividing this by the istd.
	This transforms the image data into an intensity distribution with a mean of 0 and a standard deviation of 1.
		\begin{equation}\label{ZScore}
			I_{New} = \frac{I - \mu}{\sigma}
		\end{equation}
			
	\subsubsection{MinMax}
	When applying the MinMax normalization method, the difference between the maximal and minimal intensity value (diff) of the input image is calculated. 
	Then the minimal intensity value of the image is subtracted from each pixel value. The result is then divided by the diff.
	This scales the intensities in a range from 0 to 1. 
		\begin{equation}
			I_{New} = \frac{I - I_{min}}{I_{max} - I_{min}}
		\end{equation}
		
	\subsubsection{Whitestripe}
	For the Whitestripe method equation \ref{ZScore} is likewise used. In contrast to the Z-Score normalization, $\mu$ and $\sigma$ are obtained from the intensity values of the normal appearing white matter (NAWM). 
	Thus, $\mu$ is obtained by smoothing the histogram and selecting the highest intensity peak. A 10\% segment around $\mu$ corresponds to the NAWM values of the T1w image. This segment is called the whitestripe.
	The standard deviation is then calculated from this whitestripe values.
 	By applying the equation \ref{ZScore} with the obtained $\mu$ and $\sigma$ the peak of the white matter is shifted to 0 and the intensities are scaled with $\sigma$.
	\smallskip
		
	\subsubsection{Fuzzy C-Means}
	By using the Fuzzy C-Means algorithm, a mask of the white matter pixel values is created. 
	The obtained tissue mask is used to calculate the mean of all pixel intensity values of the white matter. This mean is called $\mu$.
	Following all image intensities are scaled by $\mu$ and shifted to a constant target value $c$.
		\begin{equation}
			I_{New} = \frac{c \cdot I}{\mu}
		\end{equation}
	
	\subsubsection{Gaussian Mixture Model}
	The Guassian Mixture Model normalization fits three Gaussian distributions to the skull stripped image intensity values. 
	The mean $\mu$ of the Gaussian distribution of the white matter is then used to normalize the image with the same equation \ref{FCM} as in the Fuzzy C-Means normalization method. 
	$c$ is again the target value where the mean $\mu$ is shifted to. 
	The mean $\mu$ in a T1w image corresponding to the white matter is the peak with the highest intensity values. 
	In a T2w image the white matter mean $\mu$ is the peak with the lowest intensity values. 
	\smallskip

	\subsubsection{Histogram Matching}
	Histogram matching manipulates the histogram of the input image in such a way that the histogram of the output image matches the histogram of a given reference image. 
	This is done by mapping the cumulative distribution function of the input image to the reference image.
	As a reference image the skull stripped T1w and T2w images of a subject were used. 
	\smallskip
	

\subsection{Feature Extraction \& Classifier} 
	The following seven features were being extracted: three Coordinate Features, a T1w and T2w Intensity Feature and a T1w and T2w Gradient Intensity Feature.\\
	The classifier used was a Random Forest classifier. It consists of numerous individual decision trees acting as an ensemble learning method for classification.
	The parameters to be chosen are the estimator and the tree depth. The estimator indicates the maximal number of decision trees. 
	The tree depth indicates the depth of each tree in the forest.
	This classifier tends to over-fit and caution has to be given when applying this classifier.
	After applying a grid search the parameters for the estimator=20 and the tree depth=190 were chosen. 
	
	
\subsection{Post-Processing} 
	To prevent any biases or interfering in the results and thus being able to better analyse the influence of the different normalizations, no post-processing methods were applied in this project. 
	
	
\subsection{Conducted experiment}
	To analyse the influence of the different normalizations, all parameters have been kept for all runs. 
	For each run, one out of the six normalization methods has been applied. One additional run has been conducted with no normalization method.
	To generate reproducible results the same random seed has been set for all runs.  
	
\subsection{Evaluation}
	To evaluate the segmentations obtained within this project the {\itshape Dice Similarity Coefficient} (DSC) as well as the {\itshape Hausdorff Distance} (HD) were applied.\\
	DSC returns a value between 0 and 1, indicating the percentage of overall pixels of the resulted segmentation (SEG) overlapping the ground truth (GT). 
	A result of 1 indicates a perfect segmentation. The equation states: 
	\begin{equation}
		DICE(SEG, GT) = 2 \frac{\mid SEG \cap GT \mid}{\mid SEG \mid + \mid GT \mid}
	\end{equation}

	The HD indicates whether the margin pixels of the obtain segmentation are close to the margin pixels of the ground truth. 
	The result is the largest distance of all pixels from one point in the segmentation to the closest point in the ground truth.
	The equation states:
	\begin{equation}
		d_H (SEG, GT) = \max \left\{ \underset{x\in SEG}{\mathop{\sup }}\,\underset{y\in GT}{\mathop{\inf }}\,d(x,y),\underset{y\in GT}{\mathop{\sup }}\,\underset{x\in SEG}{\mathop{\inf }}\,d(x,y) \right\}
	\end{equation}
	Because of sensitivity of outlier pixels, only the lowest 95\% percentile of HD values are taken into account.

	
%***************************************************************************************************************	
	
	




%	% --------------------------------------------------------------
%	\begin{figure}[h]
%		\centering
%		%omit extension of file. pdflatex will convert to pdf automatically.
%		\includegraphics[width=0.4\textwidth]{haussdorfGraphics}
%		\caption{Components of the calculation of the Hausdorff distance between the green line X and the blue line Y.}
%		\label{fig:e3}
%	\end{figure}
%	% --------------------------------------------------------------


% --------------------------------------------------------------
% Results
% --------------------------------------------------------------

\section{Results}
\textbf{In depth analysis of experiment related results}

\subsection{Data}
\subsection{Model}
\subsection{Evaluation}

% --------------------------------------------------------------
% Discussion
% --------------------------------------------------------------

\section{Discussion}
\textbf{Aims of the Discussion part:
\begin{itemize}
\item Highlight importance of your work (highlight novelty /impact etc
\item To interpret your results in relation to your original problem
\item To put your work into the context of existing work
\item To present any limitations of the presented work
\item To make future recommendations
\item To provide a conclusion of the work
\end{itemize}
\begin{enumerate}
\item Importance of the work
	\begin{enumerate}
	\item Summarise your results
	\item Reiterate the importance of the work (novelty , impact etc)
	\end{enumerate}
\item Interpretation of results
	\begin{enumerate}
	\item Interpret your results focussing on the problem described in the introduction. What do the results mean for the described problem?
	\item Explain any unusual/important findings (be careful if not your original investigative subject)
	\end{enumerate}
\item Provide context
	\begin{enumerate}
	\item Describe your results in relation to others and try to explain any discrepancies
	\item Emphasize how your results support or refute your hypotheses current thinking in the field. Were results as expected? If not why and what does this mean?
	\end{enumerate}
\item Limitations of your work
	\begin{enumerate}
	\item Describe any limitations /deficiencies of your work and what impact they have on the findings
	\item Suggest possible future solutions
	\end{enumerate}
\end{enumerate} 
}

% --------------------------------------------------------------
% Conclusion
% --------------------------------------------------------------

\section{Conclusion}
\textbf{	
	\begin{itemize}
	\item Summarise your findings and relate your findings back to your hypothesis / aim / objective and to your problem.
	\item Based on your findings, suggest next steps towards solving your problem
	\end{itemize}
}
\pagebreak

% --------------------------------------------------------------
% References
% --------------------------------------------------------------

\bibliographystyle{ieeetr}
\bibliography{MIALab} 

\end{document}
